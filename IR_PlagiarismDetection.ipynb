{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IR-PlagiarismDetection.ipynb",
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DJongstra/Information_Retrieval_Assignment_3/blob/main/IR_PlagiarismDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjXxn7diu_iP"
      },
      "source": [
        "Import all needed libraries\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLlGonAdb7yF"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUDmoIiYvFe4"
      },
      "source": [
        "Drive mount"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_jIAZf9cEiI"
      },
      "source": [
        "# Mount google drive in colab:\r\n",
        "from google.cloud import storage\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nh_B70lpvJWF"
      },
      "source": [
        "Read the data of the small news article set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vU3FzItcJpb"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/IR-Assignment-3/data/news_articles_small.csv', index_col=0)\r\n",
        "print(df.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFzLFWmykTIf"
      },
      "source": [
        "All the articles in the small article dataset will be processed to a list of the terms in the articles. The words are lowercased and duplicates are removed by using a set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-pvBwR-ij75"
      },
      "source": [
        "articleList = []\r\n",
        "\r\n",
        "for index, row in df.iterrows():\r\n",
        "    temp = (row['article'].lower().split())\r\n",
        "    temp = set(temp)\r\n",
        "    articleList.append(temp)\r\n",
        "    \r\n",
        "print(articleList[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UZ5tTpEvSrv"
      },
      "source": [
        "Calculate the jaccard index between each two documents in the data set by dividing the length of the intersection with the length of the union of the two sets. Save the values to a list to use later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CrEpQqXnT_1"
      },
      "source": [
        "jaccardVals = []\r\n",
        "\r\n",
        "for doc1idx in range(len(articleList)):\r\n",
        "  doc1 = articleList[doc1idx]\r\n",
        "  doc2idx = doc1idx + 1\r\n",
        "  while doc2idx < len(articleList):\r\n",
        "    doc2 = articleList[doc2idx]\r\n",
        "    jaccard = len(doc1.intersection(doc2)) / len(doc1.union(doc2))\r\n",
        "    jaccardVals.append(jaccard)\r\n",
        "    doc2idx += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11mRB8VGvpo_"
      },
      "source": [
        "Plot the amount of values per bin, using a total of 50 bins.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v329XPSZrypo"
      },
      "source": [
        "jaccardVals = np.array(jaccardVals)\r\n",
        "sns.histplot(jaccardVals, bins=50)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGrn3fKmv2YQ"
      },
      "source": [
        "The previous graph showed a peak in a small range of the possible similarities. To see the distribution in other ranges, we leave the peak values out.\r\n",
        "\r\n",
        "From this it is clear that there are also values in the higher ranges, however there are not a lot."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPBpOnk4uifi"
      },
      "source": [
        "sns.histplot(jaccardVals[jaccardVals>0.2], bins=40)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W18E27Bkpq2I"
      },
      "source": [
        "# 2. Preprocessing of data, shingling, and minhashing to generate a signature matrix using news articles small.csv dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zs629Cm2qJua"
      },
      "source": [
        "import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHWF8ENrp1yT"
      },
      "source": [
        "!pip install mmh3\r\n",
        "!pip install snapy\r\n",
        "import string, re\r\n",
        "from snapy import MinHash, LSH"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89Qiy4dFqQIW"
      },
      "source": [
        "get content"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JgW0F_cqIX3"
      },
      "source": [
        "articleList = []\r\n",
        "\r\n",
        "for index, row in df.iterrows():\r\n",
        "  #News_ID = int(row['News_ID']) # id\r\n",
        "  article = row['article'] # lower case\r\n",
        "  #article = article.lower() # lower case\r\n",
        "  #article = article.replace(\"n't\", \" not\").replace(\"'ve\", \" have\").replace(\"'s\",\"\") # rewrite contractions\r\n",
        "  #article = re.sub(\" [^ ]*&amp[^ ]*\",\"\", article) # remove random \"&amp\"'s in text\r\n",
        "  #article = article.translate(str.maketrans('', '', string.digits)) # remove numbers?\r\n",
        "  #article = re.sub(\" +\",\" \", article) # remove double spaces\r\n",
        "  #article = article.translate(str.maketrans('', '', string.punctuation)) # remove ALL punctuation\r\n",
        "  articleList.append(article)\r\n",
        "\r\n",
        "print(articleList[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0h1ecBFFvrdo"
      },
      "source": [
        "# Create MinHash object.\r\n",
        "minhash = MinHash(articleList, n_gram=4, permutations=50, hash_bits=64, seed=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6Ji97-829Ot"
      },
      "source": [
        "# Create LSH model.\r\n",
        "lsh = LSH(minhash, range(len(articleList)), no_of_bands=50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmmZ7d7wCBeG"
      },
      "source": [
        "results = lsh.edge_list(min_jaccard=0.8, jaccard_weighted=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ly0h75s3Y4H"
      },
      "source": [
        "#for label,near_duplicates in lsh.adjacency_list(min_jaccard=0.8).items():\r\n",
        "#  if near_duplicates:\r\n",
        " #   print(\"News_id\", label, \"has near duplicates\", near_duplicates)\r\n",
        "\r\n",
        "print(\"DOC1\", \"DOC2\", \"JACCARD\")\r\n",
        "for doc1_id ,doc2_id, jaccardVal in results:\r\n",
        "  print(doc1_id ,\"\",doc2_id, \"\", jaccardVal)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}